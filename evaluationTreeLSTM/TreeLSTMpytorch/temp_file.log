2018-03-11 17:57:00,975 : INFO : LOG_FILE
2018-03-11 17:57:00,976 : INFO : _________________________________start___________________________________
2018-03-11 17:57:00,978 : INFO : Namespace(batchsize=1, cuda=False, data='data/sst/', emblr=0, epochs=10, fine_grain=1, glove='data/glove/', input_dim=300, lower=True, lr=0.05, mem_dim=150, model_name='constituency', name='default_name', num_classes=5, optim='adagrad', reg=0, saved='saved_model', seed=123, wd=0)
2018-03-11 17:57:01,006 : INFO : ==> SST vocabulary size : 21701
2018-03-11 17:57:02,464 : INFO : _param count_
2018-03-11 17:57:02,464 : INFO : torch.Size([150, 300])
2018-03-11 17:57:02,465 : INFO : torch.Size([150])
2018-03-11 17:57:02,465 : INFO : torch.Size([150, 300])
2018-03-11 17:57:02,465 : INFO : torch.Size([150])
2018-03-11 17:57:02,465 : INFO : torch.Size([150, 150])
2018-03-11 17:57:02,465 : INFO : torch.Size([150])
2018-03-11 17:57:02,465 : INFO : torch.Size([150, 150])
2018-03-11 17:57:02,465 : INFO : torch.Size([150])
2018-03-11 17:57:02,465 : INFO : torch.Size([150, 150])
2018-03-11 17:57:02,465 : INFO : torch.Size([150])
2018-03-11 17:57:02,465 : INFO : torch.Size([150, 150])
2018-03-11 17:57:02,465 : INFO : torch.Size([150])
2018-03-11 17:57:02,466 : INFO : torch.Size([150, 150])
2018-03-11 17:57:02,466 : INFO : torch.Size([150])
2018-03-11 17:57:02,466 : INFO : torch.Size([150, 150])
2018-03-11 17:57:02,466 : INFO : torch.Size([150])
2018-03-11 17:57:02,466 : INFO : torch.Size([150, 150])
2018-03-11 17:57:02,466 : INFO : torch.Size([150])
2018-03-11 17:57:02,466 : INFO : torch.Size([150, 150])
2018-03-11 17:57:02,466 : INFO : torch.Size([150])
2018-03-11 17:57:02,466 : INFO : torch.Size([5, 150])
2018-03-11 17:57:02,466 : INFO : torch.Size([5])
2018-03-11 17:57:02,466 : INFO : sum
2018-03-11 17:57:02,466 : INFO : 272255
2018-03-11 17:57:02,466 : INFO : ____________
2018-03-11 17:57:02,467 : INFO : ==> File found, loading to memory
2018-03-11 17:57:13,309 : INFO : ==> GLOVE vocabulary size: 2196016
2018-03-11 17:57:13,551 : INFO : done creating emb, quit
2018-03-11 17:57:13,552 : INFO : done preprocessing data, quit program to prevent memory leak
2018-03-11 17:57:13,552 : INFO : please run again
2018-03-11 17:59:21,321 : INFO : LOG_FILE
2018-03-11 17:59:21,321 : INFO : _________________________________start___________________________________
2018-03-11 17:59:21,324 : INFO : Namespace(batchsize=1, cuda=False, data='data/sst/', emblr=0, epochs=10, fine_grain=1, glove='data/glove/', input_dim=300, lower=True, lr=0.05, mem_dim=150, model_name='constituency', name='default_name', num_classes=5, optim='adagrad', reg=0, saved='saved_model', seed=123, wd=0)
2018-03-11 17:59:21,361 : INFO : ==> SST vocabulary size : 21701
2018-03-11 17:59:22,247 : INFO : _param count_
2018-03-11 17:59:22,248 : INFO : torch.Size([150, 300])
2018-03-11 17:59:22,248 : INFO : torch.Size([150])
2018-03-11 17:59:22,248 : INFO : torch.Size([150, 300])
2018-03-11 17:59:22,248 : INFO : torch.Size([150])
2018-03-11 17:59:22,249 : INFO : torch.Size([150, 150])
2018-03-11 17:59:22,249 : INFO : torch.Size([150])
2018-03-11 17:59:22,249 : INFO : torch.Size([150, 150])
2018-03-11 17:59:22,249 : INFO : torch.Size([150])
2018-03-11 17:59:22,249 : INFO : torch.Size([150, 150])
2018-03-11 17:59:22,249 : INFO : torch.Size([150])
2018-03-11 17:59:22,249 : INFO : torch.Size([150, 150])
2018-03-11 17:59:22,249 : INFO : torch.Size([150])
2018-03-11 17:59:22,249 : INFO : torch.Size([150, 150])
2018-03-11 17:59:22,249 : INFO : torch.Size([150])
2018-03-11 17:59:22,249 : INFO : torch.Size([150, 150])
2018-03-11 17:59:22,250 : INFO : torch.Size([150])
2018-03-11 17:59:22,250 : INFO : torch.Size([150, 150])
2018-03-11 17:59:22,250 : INFO : torch.Size([150])
2018-03-11 17:59:22,250 : INFO : torch.Size([150, 150])
2018-03-11 17:59:22,250 : INFO : torch.Size([150])
2018-03-11 17:59:22,250 : INFO : torch.Size([5, 150])
2018-03-11 17:59:22,250 : INFO : torch.Size([5])
2018-03-11 17:59:22,250 : INFO : sum
2018-03-11 17:59:22,250 : INFO : 272255
2018-03-11 17:59:22,250 : INFO : ____________
2018-03-11 18:02:38,809 : INFO : LOG_FILE
2018-03-11 18:02:38,809 : INFO : _________________________________start___________________________________
2018-03-11 18:02:38,812 : INFO : Namespace(batchsize=1, cuda=False, data='data/sst/', emblr=0, epochs=10, fine_grain=1, glove='data/glove/', input_dim=300, lower=True, lr=0.05, mem_dim=150, model_name='constituency', name='default_name', num_classes=5, optim='adagrad', reg=0, saved='saved_model', seed=123, wd=0)
2018-03-11 18:02:38,842 : INFO : ==> SST vocabulary size : 21701
2018-03-11 18:02:39,736 : INFO : _param count_
2018-03-11 18:02:39,736 : INFO : torch.Size([150, 300])
2018-03-11 18:02:39,737 : INFO : torch.Size([150])
2018-03-11 18:02:39,737 : INFO : torch.Size([150, 300])
2018-03-11 18:02:39,737 : INFO : torch.Size([150])
2018-03-11 18:02:39,737 : INFO : torch.Size([150, 150])
2018-03-11 18:02:39,737 : INFO : torch.Size([150])
2018-03-11 18:02:39,737 : INFO : torch.Size([150, 150])
2018-03-11 18:02:39,737 : INFO : torch.Size([150])
2018-03-11 18:02:39,737 : INFO : torch.Size([150, 150])
2018-03-11 18:02:39,737 : INFO : torch.Size([150])
2018-03-11 18:02:39,737 : INFO : torch.Size([150, 150])
2018-03-11 18:02:39,738 : INFO : torch.Size([150])
2018-03-11 18:02:39,738 : INFO : torch.Size([150, 150])
2018-03-11 18:02:39,738 : INFO : torch.Size([150])
2018-03-11 18:02:39,738 : INFO : torch.Size([150, 150])
2018-03-11 18:02:39,738 : INFO : torch.Size([150])
2018-03-11 18:02:39,738 : INFO : torch.Size([150, 150])
2018-03-11 18:02:39,738 : INFO : torch.Size([150])
2018-03-11 18:02:39,738 : INFO : torch.Size([150, 150])
2018-03-11 18:02:39,738 : INFO : torch.Size([150])
2018-03-11 18:02:39,738 : INFO : torch.Size([5, 150])
2018-03-11 18:02:39,738 : INFO : torch.Size([5])
2018-03-11 18:02:39,738 : INFO : sum
2018-03-11 18:02:39,739 : INFO : 272255
2018-03-11 18:02:39,739 : INFO : ____________
2018-03-11 18:03:51,069 : INFO : ==> Train loss   : 26.382572
2018-03-11 18:05:06,355 : INFO : ==> Train loss   : 21.564719
2018-03-11 18:06:24,808 : INFO : ==> Train loss   : 19.641560
2018-03-11 18:07:46,149 : INFO : ==> Train loss   : 18.274839
2018-03-11 18:09:02,603 : INFO : ==> Train loss   : 16.872210
2018-03-11 18:10:18,651 : INFO : ==> Train loss   : 15.910021
2018-03-11 18:11:34,156 : INFO : ==> Train loss   : 14.990029
2018-03-11 18:12:47,906 : INFO : ==> Train loss   : 14.171540
2018-03-11 18:14:03,906 : INFO : ==> Train loss   : 13.483392
2018-03-11 18:15:20,920 : INFO : ==> Train loss   : 12.693062
2018-03-11 18:15:20,921 : INFO : done
2018-03-11 18:21:43,299 : INFO : LOG_FILE
2018-03-11 18:21:43,299 : INFO : _________________________________start___________________________________
2018-03-11 18:21:43,302 : INFO : Namespace(batchsize=1, cuda=False, data='data/sst/', emblr=0, epochs=10, fine_grain=1, glove='data/glove/', input_dim=300, lower=True, lr=0.05, mem_dim=150, model_name='constituency', name='default_name', num_classes=5, optim='adagrad', reg=0, saved='saved_model', seed=123, wd=0)
2018-03-11 18:21:43,335 : INFO : ==> SST vocabulary size : 21701
2018-03-11 18:21:44,227 : INFO : _param count_
2018-03-11 18:21:44,227 : INFO : torch.Size([150, 300])
2018-03-11 18:21:44,228 : INFO : torch.Size([150])
2018-03-11 18:21:44,228 : INFO : torch.Size([150, 300])
2018-03-11 18:21:44,228 : INFO : torch.Size([150])
2018-03-11 18:21:44,228 : INFO : torch.Size([150, 150])
2018-03-11 18:21:44,228 : INFO : torch.Size([150])
2018-03-11 18:21:44,228 : INFO : torch.Size([150, 150])
2018-03-11 18:21:44,228 : INFO : torch.Size([150])
2018-03-11 18:21:44,228 : INFO : torch.Size([150, 150])
2018-03-11 18:21:44,229 : INFO : torch.Size([150])
2018-03-11 18:21:44,229 : INFO : torch.Size([150, 150])
2018-03-11 18:21:44,229 : INFO : torch.Size([150])
2018-03-11 18:21:44,229 : INFO : torch.Size([150, 150])
2018-03-11 18:21:44,229 : INFO : torch.Size([150])
2018-03-11 18:21:44,229 : INFO : torch.Size([150, 150])
2018-03-11 18:21:44,229 : INFO : torch.Size([150])
2018-03-11 18:21:44,229 : INFO : torch.Size([150, 150])
2018-03-11 18:21:44,229 : INFO : torch.Size([150])
2018-03-11 18:21:44,229 : INFO : torch.Size([150, 150])
2018-03-11 18:21:44,230 : INFO : torch.Size([150])
2018-03-11 18:21:44,230 : INFO : torch.Size([5, 150])
2018-03-11 18:21:44,230 : INFO : torch.Size([5])
2018-03-11 18:21:44,230 : INFO : sum
2018-03-11 18:21:44,230 : INFO : 272255
2018-03-11 18:21:44,230 : INFO : ____________
2018-03-11 18:23:01,736 : INFO : ==> Train loss   : 25.103222
2018-03-11 18:24:23,498 : INFO : ==> Train loss   : 20.554364
2018-03-11 18:25:40,890 : INFO : ==> Train loss   : 18.759472
2018-03-11 18:26:57,824 : INFO : ==> Train loss   : 17.472349
2018-03-11 18:28:14,174 : INFO : ==> Train loss   : 16.309246
2018-03-11 18:29:30,911 : INFO : ==> Train loss   : 15.362318
2018-03-11 18:30:48,218 : INFO : ==> Train loss   : 14.414774
2018-03-11 18:32:08,630 : INFO : ==> Train loss   : 13.658496
2018-03-11 18:33:32,822 : INFO : ==> Train loss   : 12.918353
2018-03-11 18:34:47,961 : INFO : ==> Train loss   : 12.315849
2018-03-11 18:34:47,961 : INFO : done
2018-03-11 18:35:03,158 : INFO : LOG_FILE
2018-03-11 18:35:03,158 : INFO : _________________________________start___________________________________
2018-03-11 18:35:03,160 : INFO : Namespace(batchsize=1, cuda=False, data='data/sst/', emblr=0, epochs=10, fine_grain=1, glove='data/glove_dev/', input_dim=300, lower=True, lr=0.05, mem_dim=150, model_name='constituency', name='default_name', num_classes=5, optim='adagrad', reg=0, saved='saved_model', seed=123, wd=0)
2018-03-11 18:35:03,176 : INFO : ==> SST vocabulary size : 5374
2018-03-11 18:35:03,626 : INFO : _param count_
2018-03-11 18:35:03,627 : INFO : torch.Size([150, 300])
2018-03-11 18:35:03,627 : INFO : torch.Size([150])
2018-03-11 18:35:03,627 : INFO : torch.Size([150, 300])
2018-03-11 18:35:03,627 : INFO : torch.Size([150])
2018-03-11 18:35:03,627 : INFO : torch.Size([150, 150])
2018-03-11 18:35:03,627 : INFO : torch.Size([150])
2018-03-11 18:35:03,627 : INFO : torch.Size([150, 150])
2018-03-11 18:35:03,628 : INFO : torch.Size([150])
2018-03-11 18:35:03,628 : INFO : torch.Size([150, 150])
2018-03-11 18:35:03,628 : INFO : torch.Size([150])
2018-03-11 18:35:03,628 : INFO : torch.Size([150, 150])
2018-03-11 18:35:03,628 : INFO : torch.Size([150])
2018-03-11 18:35:03,628 : INFO : torch.Size([150, 150])
2018-03-11 18:35:03,628 : INFO : torch.Size([150])
2018-03-11 18:35:03,628 : INFO : torch.Size([150, 150])
2018-03-11 18:35:03,628 : INFO : torch.Size([150])
2018-03-11 18:35:03,628 : INFO : torch.Size([150, 150])
2018-03-11 18:35:03,628 : INFO : torch.Size([150])
2018-03-11 18:35:03,628 : INFO : torch.Size([150, 150])
2018-03-11 18:35:03,629 : INFO : torch.Size([150])
2018-03-11 18:35:03,629 : INFO : torch.Size([5, 150])
2018-03-11 18:35:03,629 : INFO : torch.Size([5])
2018-03-11 18:35:03,629 : INFO : sum
2018-03-11 18:35:03,629 : INFO : 272255
2018-03-11 18:35:03,629 : INFO : ____________
2018-03-11 18:35:03,629 : INFO : ==> File not found, preparing, be patient
2018-03-11 18:35:04,093 : INFO : ==> GLOVE vocabulary size: 5199
2018-03-11 18:35:04,291 : INFO : done creating emb, quit
2018-03-11 18:35:04,291 : INFO : done preprocessing data, quit program to prevent memory leak
2018-03-11 18:35:04,291 : INFO : please run again
2018-03-11 18:35:12,015 : INFO : LOG_FILE
2018-03-11 18:35:12,015 : INFO : _________________________________start___________________________________
2018-03-11 18:35:12,017 : INFO : Namespace(batchsize=1, cuda=False, data='data/sst/', emblr=0, epochs=10, fine_grain=1, glove='data/glove_dev/', input_dim=300, lower=True, lr=0.05, mem_dim=150, model_name='constituency', name='default_name', num_classes=5, optim='adagrad', reg=0, saved='saved_model', seed=123, wd=0)
2018-03-11 18:35:12,034 : INFO : ==> SST vocabulary size : 5374
2018-03-11 18:35:12,500 : INFO : _param count_
2018-03-11 18:35:12,501 : INFO : torch.Size([150, 300])
2018-03-11 18:35:12,501 : INFO : torch.Size([150])
2018-03-11 18:35:12,501 : INFO : torch.Size([150, 300])
2018-03-11 18:35:12,501 : INFO : torch.Size([150])
2018-03-11 18:35:12,501 : INFO : torch.Size([150, 150])
2018-03-11 18:35:12,501 : INFO : torch.Size([150])
2018-03-11 18:35:12,501 : INFO : torch.Size([150, 150])
2018-03-11 18:35:12,501 : INFO : torch.Size([150])
2018-03-11 18:35:12,502 : INFO : torch.Size([150, 150])
2018-03-11 18:35:12,502 : INFO : torch.Size([150])
2018-03-11 18:35:12,502 : INFO : torch.Size([150, 150])
2018-03-11 18:35:12,502 : INFO : torch.Size([150])
2018-03-11 18:35:12,502 : INFO : torch.Size([150, 150])
2018-03-11 18:35:12,502 : INFO : torch.Size([150])
2018-03-11 18:35:12,502 : INFO : torch.Size([150, 150])
2018-03-11 18:35:12,502 : INFO : torch.Size([150])
2018-03-11 18:35:12,502 : INFO : torch.Size([150, 150])
2018-03-11 18:35:12,502 : INFO : torch.Size([150])
2018-03-11 18:35:12,502 : INFO : torch.Size([150, 150])
2018-03-11 18:35:12,502 : INFO : torch.Size([150])
2018-03-11 18:35:12,503 : INFO : torch.Size([5, 150])
2018-03-11 18:35:12,503 : INFO : torch.Size([5])
2018-03-11 18:35:12,503 : INFO : sum
2018-03-11 18:35:12,503 : INFO : 272255
2018-03-11 18:35:12,503 : INFO : ____________
2018-03-11 18:41:41,063 : INFO : LOG_FILE
2018-03-11 18:41:41,063 : INFO : _________________________________start___________________________________
2018-03-11 18:41:41,065 : INFO : Namespace(batchsize=1, cuda=False, data='data/sst/', emblr=0, epochs=10, fine_grain=1, glove='data/glove_dev/', input_dim=300, lower=True, lr=0.05, mem_dim=150, model_name='constituency', name='default_name', num_classes=5, optim='adagrad', reg=0, saved='saved_model', seed=123, wd=0)
2018-03-11 18:41:41,081 : INFO : ==> SST vocabulary size : 5374
2018-03-11 18:41:41,532 : INFO : _param count_
2018-03-11 18:41:41,533 : INFO : torch.Size([150, 300])
2018-03-11 18:41:41,533 : INFO : torch.Size([150])
2018-03-11 18:41:41,533 : INFO : torch.Size([150, 300])
2018-03-11 18:41:41,533 : INFO : torch.Size([150])
2018-03-11 18:41:41,533 : INFO : torch.Size([150, 150])
2018-03-11 18:41:41,533 : INFO : torch.Size([150])
2018-03-11 18:41:41,533 : INFO : torch.Size([150, 150])
2018-03-11 18:41:41,533 : INFO : torch.Size([150])
2018-03-11 18:41:41,534 : INFO : torch.Size([150, 150])
2018-03-11 18:41:41,534 : INFO : torch.Size([150])
2018-03-11 18:41:41,534 : INFO : torch.Size([150, 150])
2018-03-11 18:41:41,534 : INFO : torch.Size([150])
2018-03-11 18:41:41,534 : INFO : torch.Size([150, 150])
2018-03-11 18:41:41,534 : INFO : torch.Size([150])
2018-03-11 18:41:41,534 : INFO : torch.Size([150, 150])
2018-03-11 18:41:41,534 : INFO : torch.Size([150])
2018-03-11 18:41:41,534 : INFO : torch.Size([150, 150])
2018-03-11 18:41:41,534 : INFO : torch.Size([150])
2018-03-11 18:41:41,534 : INFO : torch.Size([150, 150])
2018-03-11 18:41:41,535 : INFO : torch.Size([150])
2018-03-11 18:41:41,535 : INFO : torch.Size([5, 150])
2018-03-11 18:41:41,535 : INFO : torch.Size([5])
2018-03-11 18:41:41,535 : INFO : sum
2018-03-11 18:41:41,535 : INFO : 272255
2018-03-11 18:41:41,535 : INFO : ____________
2018-03-11 18:42:39,434 : INFO : LOG_FILE
2018-03-11 18:42:39,434 : INFO : _________________________________start___________________________________
2018-03-11 18:42:39,436 : INFO : Namespace(batchsize=1, cuda=False, data='data/sst/', emblr=0, epochs=10, fine_grain=1, glove='data/glove_dev/', input_dim=300, lower=True, lr=0.05, mem_dim=150, model_name='constituency', name='default_name', num_classes=5, optim='adagrad', reg=0, saved='saved_model', seed=123, wd=0)
2018-03-11 18:42:39,453 : INFO : ==> SST vocabulary size : 5374
2018-03-11 18:42:39,931 : INFO : _param count_
2018-03-11 18:42:39,931 : INFO : torch.Size([150, 300])
2018-03-11 18:42:39,931 : INFO : torch.Size([150])
2018-03-11 18:42:39,932 : INFO : torch.Size([150, 300])
2018-03-11 18:42:39,932 : INFO : torch.Size([150])
2018-03-11 18:42:39,932 : INFO : torch.Size([150, 150])
2018-03-11 18:42:39,932 : INFO : torch.Size([150])
2018-03-11 18:42:39,932 : INFO : torch.Size([150, 150])
2018-03-11 18:42:39,932 : INFO : torch.Size([150])
2018-03-11 18:42:39,932 : INFO : torch.Size([150, 150])
2018-03-11 18:42:39,932 : INFO : torch.Size([150])
2018-03-11 18:42:39,933 : INFO : torch.Size([150, 150])
2018-03-11 18:42:39,933 : INFO : torch.Size([150])
2018-03-11 18:42:39,933 : INFO : torch.Size([150, 150])
2018-03-11 18:42:39,933 : INFO : torch.Size([150])
2018-03-11 18:42:39,933 : INFO : torch.Size([150, 150])
2018-03-11 18:42:39,933 : INFO : torch.Size([150])
2018-03-11 18:42:39,933 : INFO : torch.Size([150, 150])
2018-03-11 18:42:39,933 : INFO : torch.Size([150])
2018-03-11 18:42:39,934 : INFO : torch.Size([150, 150])
2018-03-11 18:42:39,934 : INFO : torch.Size([150])
2018-03-11 18:42:39,934 : INFO : torch.Size([5, 150])
2018-03-11 18:42:39,934 : INFO : torch.Size([5])
2018-03-11 18:42:39,934 : INFO : sum
2018-03-11 18:42:39,934 : INFO : 272255
2018-03-11 18:42:39,934 : INFO : ____________
2018-03-11 18:42:39,934 : INFO : ==> File found, loading to memory
2018-03-11 18:42:39,946 : INFO : ==> GLOVE vocabulary size: 5199
2018-03-11 18:43:55,376 : INFO : LOG_FILE
2018-03-11 18:43:55,377 : INFO : _________________________________start___________________________________
2018-03-11 18:43:55,380 : INFO : Namespace(batchsize=1, cuda=False, data='data/sst/', emblr=0, epochs=10, fine_grain=1, glove='data/glove_dev/', input_dim=300, lower=True, lr=0.05, mem_dim=150, model_name='constituency', name='default_name', num_classes=5, optim='adagrad', reg=0, saved='saved_model', seed=123, wd=0)
2018-03-11 18:43:55,397 : INFO : ==> SST vocabulary size : 5374
2018-03-11 18:43:55,860 : INFO : _param count_
2018-03-11 18:43:55,861 : INFO : torch.Size([150, 300])
2018-03-11 18:43:55,861 : INFO : torch.Size([150])
2018-03-11 18:43:55,861 : INFO : torch.Size([150, 300])
2018-03-11 18:43:55,861 : INFO : torch.Size([150])
2018-03-11 18:43:55,861 : INFO : torch.Size([150, 150])
2018-03-11 18:43:55,861 : INFO : torch.Size([150])
2018-03-11 18:43:55,861 : INFO : torch.Size([150, 150])
2018-03-11 18:43:55,861 : INFO : torch.Size([150])
2018-03-11 18:43:55,861 : INFO : torch.Size([150, 150])
2018-03-11 18:43:55,861 : INFO : torch.Size([150])
2018-03-11 18:43:55,862 : INFO : torch.Size([150, 150])
2018-03-11 18:43:55,862 : INFO : torch.Size([150])
2018-03-11 18:43:55,862 : INFO : torch.Size([150, 150])
2018-03-11 18:43:55,862 : INFO : torch.Size([150])
2018-03-11 18:43:55,862 : INFO : torch.Size([150, 150])
2018-03-11 18:43:55,862 : INFO : torch.Size([150])
2018-03-11 18:43:55,862 : INFO : torch.Size([150, 150])
2018-03-11 18:43:55,862 : INFO : torch.Size([150])
2018-03-11 18:43:55,862 : INFO : torch.Size([150, 150])
2018-03-11 18:43:55,862 : INFO : torch.Size([150])
2018-03-11 18:43:55,862 : INFO : torch.Size([5, 150])
2018-03-11 18:43:55,862 : INFO : torch.Size([5])
2018-03-11 18:43:55,862 : INFO : sum
2018-03-11 18:43:55,862 : INFO : 272255
2018-03-11 18:43:55,863 : INFO : ____________
2018-03-11 18:43:55,863 : INFO : ==> File found, loading to memory
2018-03-11 18:43:55,874 : INFO : ==> GLOVE vocabulary size: 5199
2018-03-11 18:43:55,874 : INFO : ==> GLOVE embedding size: 299
2018-03-11 18:43:56,066 : INFO : done creating emb, quit
2018-03-11 18:43:56,067 : INFO : done preprocessing data, quit program to prevent memory leak
2018-03-11 18:43:56,067 : INFO : please run again
2018-03-11 18:47:13,232 : INFO : LOG_FILE
2018-03-11 18:47:13,232 : INFO : _________________________________start___________________________________
2018-03-11 18:47:13,234 : INFO : Namespace(batchsize=1, cuda=False, data='data/sst/', emblr=0, epochs=10, fine_grain=1, glove='data/glove_dev/', input_dim=300, lower=True, lr=0.05, mem_dim=150, model_name='constituency', name='default_name', num_classes=5, optim='adagrad', reg=0, saved='saved_model', seed=123, wd=0)
2018-03-11 18:47:13,251 : INFO : ==> SST vocabulary size : 5374
2018-03-11 18:47:13,725 : INFO : _param count_
2018-03-11 18:47:13,726 : INFO : torch.Size([150, 300])
2018-03-11 18:47:13,726 : INFO : torch.Size([150])
2018-03-11 18:47:13,726 : INFO : torch.Size([150, 300])
2018-03-11 18:47:13,726 : INFO : torch.Size([150])
2018-03-11 18:47:13,726 : INFO : torch.Size([150, 150])
2018-03-11 18:47:13,726 : INFO : torch.Size([150])
2018-03-11 18:47:13,726 : INFO : torch.Size([150, 150])
2018-03-11 18:47:13,726 : INFO : torch.Size([150])
2018-03-11 18:47:13,726 : INFO : torch.Size([150, 150])
2018-03-11 18:47:13,727 : INFO : torch.Size([150])
2018-03-11 18:47:13,727 : INFO : torch.Size([150, 150])
2018-03-11 18:47:13,727 : INFO : torch.Size([150])
2018-03-11 18:47:13,727 : INFO : torch.Size([150, 150])
2018-03-11 18:47:13,727 : INFO : torch.Size([150])
2018-03-11 18:47:13,727 : INFO : torch.Size([150, 150])
2018-03-11 18:47:13,727 : INFO : torch.Size([150])
2018-03-11 18:47:13,727 : INFO : torch.Size([150, 150])
2018-03-11 18:47:13,727 : INFO : torch.Size([150])
2018-03-11 18:47:13,727 : INFO : torch.Size([150, 150])
2018-03-11 18:47:13,727 : INFO : torch.Size([150])
2018-03-11 18:47:13,727 : INFO : torch.Size([5, 150])
2018-03-11 18:47:13,728 : INFO : torch.Size([5])
2018-03-11 18:47:13,728 : INFO : sum
2018-03-11 18:47:13,728 : INFO : 272255
2018-03-11 18:47:13,728 : INFO : ____________
2018-03-11 18:47:13,728 : INFO : ==> File found, loading to memory
2018-03-11 18:47:13,739 : INFO : ==> GLOVE vocabulary size: 5199
2018-03-11 18:47:13,739 : INFO : ==> GLOVE embedding size: 299
2018-03-11 18:47:13,938 : INFO : done creating emb, quit
2018-03-11 18:47:13,939 : INFO : done preprocessing data, quit program to prevent memory leak
2018-03-11 18:47:13,939 : INFO : please run again
2018-03-11 18:48:08,106 : INFO : LOG_FILE
2018-03-11 18:48:08,107 : INFO : _________________________________start___________________________________
2018-03-11 18:48:08,109 : INFO : Namespace(batchsize=1, cuda=False, data='data/sst/', emblr=0, epochs=10, fine_grain=1, glove='data/glove_dev/', input_dim=300, lower=True, lr=0.05, mem_dim=150, model_name='constituency', name='default_name', num_classes=5, optim='adagrad', reg=0, saved='saved_model', seed=123, wd=0)
2018-03-11 18:48:08,125 : INFO : ==> SST vocabulary size : 5374
2018-03-11 18:48:08,586 : INFO : _param count_
2018-03-11 18:48:08,587 : INFO : torch.Size([150, 300])
2018-03-11 18:48:08,587 : INFO : torch.Size([150])
2018-03-11 18:48:08,587 : INFO : torch.Size([150, 300])
2018-03-11 18:48:08,587 : INFO : torch.Size([150])
2018-03-11 18:48:08,587 : INFO : torch.Size([150, 150])
2018-03-11 18:48:08,587 : INFO : torch.Size([150])
2018-03-11 18:48:08,587 : INFO : torch.Size([150, 150])
2018-03-11 18:48:08,587 : INFO : torch.Size([150])
2018-03-11 18:48:08,587 : INFO : torch.Size([150, 150])
2018-03-11 18:48:08,587 : INFO : torch.Size([150])
2018-03-11 18:48:08,588 : INFO : torch.Size([150, 150])
2018-03-11 18:48:08,588 : INFO : torch.Size([150])
2018-03-11 18:48:08,588 : INFO : torch.Size([150, 150])
2018-03-11 18:48:08,588 : INFO : torch.Size([150])
2018-03-11 18:48:08,588 : INFO : torch.Size([150, 150])
2018-03-11 18:48:08,588 : INFO : torch.Size([150])
2018-03-11 18:48:08,588 : INFO : torch.Size([150, 150])
2018-03-11 18:48:08,588 : INFO : torch.Size([150])
2018-03-11 18:48:08,588 : INFO : torch.Size([150, 150])
2018-03-11 18:48:08,588 : INFO : torch.Size([150])
2018-03-11 18:48:08,588 : INFO : torch.Size([5, 150])
2018-03-11 18:48:08,588 : INFO : torch.Size([5])
2018-03-11 18:48:08,588 : INFO : sum
2018-03-11 18:48:08,589 : INFO : 272255
2018-03-11 18:48:08,589 : INFO : ____________
2018-03-11 18:48:08,589 : INFO : ==> File not found, preparing, be patient
2018-03-11 18:48:08,608 : INFO : ====== dim is wrong 299
2018-03-11 18:48:09,049 : INFO : ==> GLOVE vocabulary size: 5199
2018-03-11 18:48:09,050 : INFO : ==> GLOVE embedding size: 299
2018-03-11 18:48:09,252 : INFO : done creating emb, quit
2018-03-11 18:48:09,252 : INFO : done preprocessing data, quit program to prevent memory leak
2018-03-11 18:48:09,252 : INFO : please run again
2018-03-11 18:54:21,149 : INFO : LOG_FILE
2018-03-11 18:54:21,150 : INFO : _________________________________start___________________________________
2018-03-11 18:54:21,152 : INFO : Namespace(batchsize=1, cuda=False, data='data/sst/', emblr=0, epochs=10, fine_grain=1, glove='data/glove_dev/', input_dim=300, lower=True, lr=0.05, mem_dim=150, model_name='constituency', name='default_name', num_classes=5, optim='adagrad', reg=0, saved='saved_model', seed=123, wd=0)
2018-03-11 18:54:21,169 : INFO : ==> SST vocabulary size : 5374
2018-03-11 18:54:21,634 : INFO : _param count_
2018-03-11 18:54:21,635 : INFO : torch.Size([150, 300])
2018-03-11 18:54:21,635 : INFO : torch.Size([150])
2018-03-11 18:54:21,635 : INFO : torch.Size([150, 300])
2018-03-11 18:54:21,635 : INFO : torch.Size([150])
2018-03-11 18:54:21,635 : INFO : torch.Size([150, 150])
2018-03-11 18:54:21,635 : INFO : torch.Size([150])
2018-03-11 18:54:21,635 : INFO : torch.Size([150, 150])
2018-03-11 18:54:21,636 : INFO : torch.Size([150])
2018-03-11 18:54:21,636 : INFO : torch.Size([150, 150])
2018-03-11 18:54:21,636 : INFO : torch.Size([150])
2018-03-11 18:54:21,636 : INFO : torch.Size([150, 150])
2018-03-11 18:54:21,636 : INFO : torch.Size([150])
2018-03-11 18:54:21,636 : INFO : torch.Size([150, 150])
2018-03-11 18:54:21,636 : INFO : torch.Size([150])
2018-03-11 18:54:21,636 : INFO : torch.Size([150, 150])
2018-03-11 18:54:21,636 : INFO : torch.Size([150])
2018-03-11 18:54:21,636 : INFO : torch.Size([150, 150])
2018-03-11 18:54:21,636 : INFO : torch.Size([150])
2018-03-11 18:54:21,636 : INFO : torch.Size([150, 150])
2018-03-11 18:54:21,637 : INFO : torch.Size([150])
2018-03-11 18:54:21,637 : INFO : torch.Size([5, 150])
2018-03-11 18:54:21,637 : INFO : torch.Size([5])
2018-03-11 18:54:21,637 : INFO : sum
2018-03-11 18:54:21,637 : INFO : 272255
2018-03-11 18:54:21,637 : INFO : ____________
2018-03-11 18:54:21,637 : INFO : ==> File not found, preparing, be patient
2018-03-11 18:54:21,658 : INFO : ====== dim is wrong 300
2018-03-11 18:54:22,104 : INFO : ==> GLOVE vocabulary size: 5264
2018-03-11 18:54:22,104 : INFO : ==> GLOVE embedding size: 300
2018-03-11 18:54:22,143 : INFO : done creating emb, quit
2018-03-11 18:54:22,143 : INFO : done preprocessing data, quit program to prevent memory leak
2018-03-11 18:54:22,143 : INFO : please run again
2018-03-11 18:54:31,226 : INFO : LOG_FILE
2018-03-11 18:54:31,226 : INFO : _________________________________start___________________________________
2018-03-11 18:54:31,228 : INFO : Namespace(batchsize=1, cuda=False, data='data/sst/', emblr=0, epochs=10, fine_grain=1, glove='data/glove_dev/', input_dim=300, lower=True, lr=0.05, mem_dim=150, model_name='constituency', name='default_name', num_classes=5, optim='adagrad', reg=0, saved='saved_model', seed=123, wd=0)
2018-03-11 18:54:31,244 : INFO : ==> SST vocabulary size : 5374
2018-03-11 18:54:31,708 : INFO : _param count_
2018-03-11 18:54:31,709 : INFO : torch.Size([150, 300])
2018-03-11 18:54:31,709 : INFO : torch.Size([150])
2018-03-11 18:54:31,709 : INFO : torch.Size([150, 300])
2018-03-11 18:54:31,709 : INFO : torch.Size([150])
2018-03-11 18:54:31,709 : INFO : torch.Size([150, 150])
2018-03-11 18:54:31,709 : INFO : torch.Size([150])
2018-03-11 18:54:31,709 : INFO : torch.Size([150, 150])
2018-03-11 18:54:31,710 : INFO : torch.Size([150])
2018-03-11 18:54:31,710 : INFO : torch.Size([150, 150])
2018-03-11 18:54:31,710 : INFO : torch.Size([150])
2018-03-11 18:54:31,710 : INFO : torch.Size([150, 150])
2018-03-11 18:54:31,710 : INFO : torch.Size([150])
2018-03-11 18:54:31,710 : INFO : torch.Size([150, 150])
2018-03-11 18:54:31,710 : INFO : torch.Size([150])
2018-03-11 18:54:31,710 : INFO : torch.Size([150, 150])
2018-03-11 18:54:31,710 : INFO : torch.Size([150])
2018-03-11 18:54:31,710 : INFO : torch.Size([150, 150])
2018-03-11 18:54:31,710 : INFO : torch.Size([150])
2018-03-11 18:54:31,710 : INFO : torch.Size([150, 150])
2018-03-11 18:54:31,710 : INFO : torch.Size([150])
2018-03-11 18:54:31,711 : INFO : torch.Size([5, 150])
2018-03-11 18:54:31,711 : INFO : torch.Size([5])
2018-03-11 18:54:31,711 : INFO : sum
2018-03-11 18:54:31,711 : INFO : 272255
2018-03-11 18:54:31,711 : INFO : ____________
2018-03-11 18:58:06,268 : INFO : LOG_FILE
2018-03-11 18:58:06,269 : INFO : _________________________________start___________________________________
2018-03-11 18:58:06,271 : INFO : Namespace(batchsize=1, cuda=False, data='data/sst/', emblr=0, epochs=10, fine_grain=1, glove='data/glove/', input_dim=300, lower=True, lr=0.05, mem_dim=150, model_name='constituency', name='default_name', num_classes=5, optim='adagrad', reg=0, saved='saved_model', seed=123, wd=0)
2018-03-11 18:58:06,301 : INFO : ==> SST vocabulary size : 21701
2018-03-11 18:58:07,803 : INFO : _param count_
2018-03-11 18:58:07,803 : INFO : torch.Size([150, 300])
2018-03-11 18:58:07,804 : INFO : torch.Size([150])
2018-03-11 18:58:07,804 : INFO : torch.Size([150, 300])
2018-03-11 18:58:07,804 : INFO : torch.Size([150])
2018-03-11 18:58:07,804 : INFO : torch.Size([150, 150])
2018-03-11 18:58:07,804 : INFO : torch.Size([150])
2018-03-11 18:58:07,804 : INFO : torch.Size([150, 150])
2018-03-11 18:58:07,804 : INFO : torch.Size([150])
2018-03-11 18:58:07,804 : INFO : torch.Size([150, 150])
2018-03-11 18:58:07,804 : INFO : torch.Size([150])
2018-03-11 18:58:07,804 : INFO : torch.Size([150, 150])
2018-03-11 18:58:07,805 : INFO : torch.Size([150])
2018-03-11 18:58:07,805 : INFO : torch.Size([150, 150])
2018-03-11 18:58:07,805 : INFO : torch.Size([150])
2018-03-11 18:58:07,805 : INFO : torch.Size([150, 150])
2018-03-11 18:58:07,805 : INFO : torch.Size([150])
2018-03-11 18:58:07,805 : INFO : torch.Size([150, 150])
2018-03-11 18:58:07,805 : INFO : torch.Size([150])
2018-03-11 18:58:07,805 : INFO : torch.Size([150, 150])
2018-03-11 18:58:07,805 : INFO : torch.Size([150])
2018-03-11 18:58:07,805 : INFO : torch.Size([5, 150])
2018-03-11 18:58:07,805 : INFO : torch.Size([5])
2018-03-11 18:58:07,806 : INFO : sum
2018-03-11 18:58:07,806 : INFO : 272255
2018-03-11 18:58:07,806 : INFO : ____________
2018-03-11 18:58:07,806 : INFO : ==> File found, loading to memory
2018-03-11 18:58:56,084 : INFO : LOG_FILE
2018-03-11 18:58:56,085 : INFO : _________________________________start___________________________________
2018-03-11 18:58:56,087 : INFO : Namespace(batchsize=1, cuda=False, data='data/sst/', emblr=0, epochs=10, fine_grain=1, glove='data/glove/', input_dim=300, lower=True, lr=0.05, mem_dim=150, model_name='constituency', name='default_name', num_classes=5, optim='adagrad', reg=0, saved='saved_model', seed=123, wd=0)
2018-03-11 18:58:56,120 : INFO : ==> SST vocabulary size : 21701
2018-03-11 18:58:57,657 : INFO : _param count_
2018-03-11 18:58:57,657 : INFO : torch.Size([150, 300])
2018-03-11 18:58:57,658 : INFO : torch.Size([150])
2018-03-11 18:58:57,658 : INFO : torch.Size([150, 300])
2018-03-11 18:58:57,658 : INFO : torch.Size([150])
2018-03-11 18:58:57,658 : INFO : torch.Size([150, 150])
2018-03-11 18:58:57,658 : INFO : torch.Size([150])
2018-03-11 18:58:57,658 : INFO : torch.Size([150, 150])
2018-03-11 18:58:57,658 : INFO : torch.Size([150])
2018-03-11 18:58:57,658 : INFO : torch.Size([150, 150])
2018-03-11 18:58:57,658 : INFO : torch.Size([150])
2018-03-11 18:58:57,658 : INFO : torch.Size([150, 150])
2018-03-11 18:58:57,658 : INFO : torch.Size([150])
2018-03-11 18:58:57,659 : INFO : torch.Size([150, 150])
2018-03-11 18:58:57,659 : INFO : torch.Size([150])
2018-03-11 18:58:57,659 : INFO : torch.Size([150, 150])
2018-03-11 18:58:57,659 : INFO : torch.Size([150])
2018-03-11 18:58:57,659 : INFO : torch.Size([150, 150])
2018-03-11 18:58:57,659 : INFO : torch.Size([150])
2018-03-11 18:58:57,659 : INFO : torch.Size([150, 150])
2018-03-11 18:58:57,659 : INFO : torch.Size([150])
2018-03-11 18:58:57,659 : INFO : torch.Size([5, 150])
2018-03-11 18:58:57,659 : INFO : torch.Size([5])
2018-03-11 18:58:57,659 : INFO : sum
2018-03-11 18:58:57,659 : INFO : 272255
2018-03-11 18:58:57,660 : INFO : ____________
2018-03-11 18:58:57,660 : INFO : ==> File not found, preparing, be patient
2018-03-11 19:02:24,333 : INFO : ==> GLOVE vocabulary size: 2196016
2018-03-11 19:02:24,604 : INFO : done creating emb, quit
2018-03-11 19:02:24,604 : INFO : done preprocessing data, quit program to prevent memory leak
2018-03-11 19:02:24,604 : INFO : please run again
2018-03-11 19:02:28,647 : INFO : LOG_FILE
2018-03-11 19:02:28,647 : INFO : _________________________________start___________________________________
2018-03-11 19:02:28,650 : INFO : Namespace(batchsize=1, cuda=False, data='data/sst/', emblr=0, epochs=10, fine_grain=1, glove='data/glove/', input_dim=300, lower=True, lr=0.05, mem_dim=150, model_name='constituency', name='default_name', num_classes=5, optim='adagrad', reg=0, saved='saved_model', seed=123, wd=0)
2018-03-11 19:02:28,680 : INFO : ==> SST vocabulary size : 21701
2018-03-11 19:02:29,573 : INFO : _param count_
2018-03-11 19:02:29,579 : INFO : torch.Size([150, 300])
2018-03-11 19:02:29,579 : INFO : torch.Size([150])
2018-03-11 19:02:29,579 : INFO : torch.Size([150, 300])
2018-03-11 19:02:29,579 : INFO : torch.Size([150])
2018-03-11 19:02:29,579 : INFO : torch.Size([150, 150])
2018-03-11 19:02:29,579 : INFO : torch.Size([150])
2018-03-11 19:02:29,579 : INFO : torch.Size([150, 150])
2018-03-11 19:02:29,580 : INFO : torch.Size([150])
2018-03-11 19:02:29,580 : INFO : torch.Size([150, 150])
2018-03-11 19:02:29,580 : INFO : torch.Size([150])
2018-03-11 19:02:29,580 : INFO : torch.Size([150, 150])
2018-03-11 19:02:29,580 : INFO : torch.Size([150])
2018-03-11 19:02:29,580 : INFO : torch.Size([150, 150])
2018-03-11 19:02:29,580 : INFO : torch.Size([150])
2018-03-11 19:02:29,580 : INFO : torch.Size([150, 150])
2018-03-11 19:02:29,580 : INFO : torch.Size([150])
2018-03-11 19:02:29,580 : INFO : torch.Size([150, 150])
2018-03-11 19:02:29,580 : INFO : torch.Size([150])
2018-03-11 19:02:29,580 : INFO : torch.Size([150, 150])
2018-03-11 19:02:29,580 : INFO : torch.Size([150])
2018-03-11 19:02:29,581 : INFO : torch.Size([5, 150])
2018-03-11 19:02:29,581 : INFO : torch.Size([5])
2018-03-11 19:02:29,581 : INFO : sum
2018-03-11 19:02:29,581 : INFO : 272255
2018-03-11 19:02:29,581 : INFO : ____________
2018-03-11 19:03:46,827 : INFO : ==> Train loss   : 24.983287
2018-03-11 19:05:03,909 : INFO : ==> Train loss   : 20.377126
2018-03-11 19:06:17,627 : INFO : ==> Train loss   : 18.552840
2018-03-11 19:07:31,309 : INFO : ==> Train loss   : 17.171531
2018-03-11 19:08:46,285 : INFO : ==> Train loss   : 15.942633
2018-03-11 19:10:00,317 : INFO : ==> Train loss   : 14.915475
2018-03-11 19:11:13,190 : INFO : ==> Train loss   : 14.117667
2018-03-11 19:12:25,896 : INFO : ==> Train loss   : 13.315549
2018-03-11 19:13:38,546 : INFO : ==> Train loss   : 12.553825
2018-03-11 19:14:52,607 : INFO : ==> Train loss   : 11.660978
2018-03-11 19:14:52,608 : INFO : done
2018-03-11 19:16:58,324 : INFO : LOG_FILE
2018-03-11 19:16:58,324 : INFO : _________________________________start___________________________________
2018-03-11 19:16:58,326 : INFO : Namespace(batchsize=1, cuda=False, data='data/sst/', emblr=0, epochs=10, fine_grain=1, glove='data/glove/', input_dim=300, lower=True, lr=0.05, mem_dim=150, model_name='constituency', name='default_name', num_classes=5, optim='adagrad', reg=0, saved='saved_model', seed=123, wd=0)
2018-03-11 19:16:58,357 : INFO : ==> SST vocabulary size : 21701
2018-03-11 19:16:59,252 : INFO : _param count_
2018-03-11 19:16:59,252 : INFO : torch.Size([150, 300])
2018-03-11 19:16:59,253 : INFO : torch.Size([150])
2018-03-11 19:16:59,253 : INFO : torch.Size([150, 300])
2018-03-11 19:16:59,253 : INFO : torch.Size([150])
2018-03-11 19:16:59,253 : INFO : torch.Size([150, 150])
2018-03-11 19:16:59,253 : INFO : torch.Size([150])
2018-03-11 19:16:59,253 : INFO : torch.Size([150, 150])
2018-03-11 19:16:59,253 : INFO : torch.Size([150])
2018-03-11 19:16:59,253 : INFO : torch.Size([150, 150])
2018-03-11 19:16:59,253 : INFO : torch.Size([150])
2018-03-11 19:16:59,253 : INFO : torch.Size([150, 150])
2018-03-11 19:16:59,254 : INFO : torch.Size([150])
2018-03-11 19:16:59,254 : INFO : torch.Size([150, 150])
2018-03-11 19:16:59,254 : INFO : torch.Size([150])
2018-03-11 19:16:59,254 : INFO : torch.Size([150, 150])
2018-03-11 19:16:59,254 : INFO : torch.Size([150])
2018-03-11 19:16:59,254 : INFO : torch.Size([150, 150])
2018-03-11 19:16:59,254 : INFO : torch.Size([150])
2018-03-11 19:16:59,254 : INFO : torch.Size([150, 150])
2018-03-11 19:16:59,254 : INFO : torch.Size([150])
2018-03-11 19:16:59,254 : INFO : torch.Size([5, 150])
2018-03-11 19:16:59,254 : INFO : torch.Size([5])
2018-03-11 19:16:59,254 : INFO : sum
2018-03-11 19:16:59,254 : INFO : 272255
2018-03-11 19:16:59,255 : INFO : ____________
2018-03-11 19:18:11,280 : INFO : ==> Train loss   : 24.939029
2018-03-11 19:19:23,202 : INFO : ==> Train loss   : 20.491188
2018-03-11 19:20:35,439 : INFO : ==> Train loss   : 18.605994
2018-03-11 19:21:47,682 : INFO : ==> Train loss   : 17.264849
2018-03-11 19:23:01,183 : INFO : ==> Train loss   : 16.259281
2018-03-11 19:24:11,743 : INFO : ==> Train loss   : 15.083500
2018-03-11 19:25:19,584 : INFO : ==> Train loss   : 14.219474
2018-03-11 19:26:24,527 : INFO : ==> Train loss   : 13.585342
2018-03-11 19:27:29,517 : INFO : ==> Train loss   : 12.642008
2018-03-11 19:28:34,709 : INFO : ==> Train loss   : 12.101974
2018-03-11 19:28:34,709 : INFO : done
2018-03-11 19:34:47,523 : INFO : LOG_FILE
2018-03-11 19:34:47,524 : INFO : _________________________________start___________________________________
2018-03-11 19:34:47,527 : INFO : Namespace(batchsize=1, cuda=False, data='data/sst/', emblr=0, epochs=30, fine_grain=1, glove='data/glove/', input_dim=300, lower=True, lr=0.05, mem_dim=150, model_name='constituency', name='default_name', num_classes=5, optim='adagrad', reg=0, saved='saved_model', seed=123, wd=0)
2018-03-11 19:34:47,561 : INFO : ==> SST vocabulary size : 21701
2018-03-11 19:34:48,478 : INFO : _param count_
2018-03-11 19:34:48,478 : INFO : torch.Size([150, 300])
2018-03-11 19:34:48,478 : INFO : torch.Size([150])
2018-03-11 19:34:48,479 : INFO : torch.Size([150, 300])
2018-03-11 19:34:48,479 : INFO : torch.Size([150])
2018-03-11 19:34:48,479 : INFO : torch.Size([150, 150])
2018-03-11 19:34:48,479 : INFO : torch.Size([150])
2018-03-11 19:34:48,479 : INFO : torch.Size([150, 150])
2018-03-11 19:34:48,479 : INFO : torch.Size([150])
2018-03-11 19:34:48,479 : INFO : torch.Size([150, 150])
2018-03-11 19:34:48,479 : INFO : torch.Size([150])
2018-03-11 19:34:48,479 : INFO : torch.Size([150, 150])
2018-03-11 19:34:48,479 : INFO : torch.Size([150])
2018-03-11 19:34:48,480 : INFO : torch.Size([150, 150])
2018-03-11 19:34:48,480 : INFO : torch.Size([150])
2018-03-11 19:34:48,480 : INFO : torch.Size([150, 150])
2018-03-11 19:34:48,480 : INFO : torch.Size([150])
2018-03-11 19:34:48,480 : INFO : torch.Size([150, 150])
2018-03-11 19:34:48,480 : INFO : torch.Size([150])
2018-03-11 19:34:48,480 : INFO : torch.Size([150, 150])
2018-03-11 19:34:48,480 : INFO : torch.Size([150])
2018-03-11 19:34:48,480 : INFO : torch.Size([5, 150])
2018-03-11 19:34:48,480 : INFO : torch.Size([5])
2018-03-11 19:34:48,480 : INFO : sum
2018-03-11 19:34:48,480 : INFO : 272255
2018-03-11 19:34:48,481 : INFO : ____________
2018-03-11 19:36:01,167 : INFO : ==> Train loss   : 25.218865
2018-03-11 19:37:21,116 : INFO : ==> Train loss   : 20.536118
2018-03-11 19:38:40,802 : INFO : ==> Train loss   : 18.898189
2018-03-11 19:39:54,594 : INFO : ==> Train loss   : 17.794133
2018-03-11 19:41:07,749 : INFO : ==> Train loss   : 16.737368
2018-03-11 19:42:20,965 : INFO : ==> Train loss   : 15.858181
2018-03-11 19:43:34,175 : INFO : ==> Train loss   : 15.016700
2018-03-11 19:44:48,895 : INFO : ==> Train loss   : 14.273290
2018-03-11 19:46:00,385 : INFO : ==> Train loss   : 13.476012
2018-03-11 19:47:12,129 : INFO : ==> Train loss   : 12.919160
2018-03-11 19:48:24,035 : INFO : ==> Train loss   : 12.263275
2018-03-11 19:49:36,010 : INFO : ==> Train loss   : 11.607812
2018-03-11 19:50:47,773 : INFO : ==> Train loss   : 11.054607
2018-03-11 19:51:59,618 : INFO : ==> Train loss   : 10.514497
2018-03-11 19:53:11,512 : INFO : ==> Train loss   : 10.201130
2018-03-11 19:54:23,394 : INFO : ==> Train loss   : 9.618248
2018-03-11 19:55:35,827 : INFO : ==> Train loss   : 9.103827
2018-03-11 19:56:47,928 : INFO : ==> Train loss   : 8.858252
2018-03-11 19:57:59,893 : INFO : ==> Train loss   : 8.217143
2018-03-11 19:59:25,453 : INFO : ==> Train loss   : 7.976442
2018-03-11 20:00:39,202 : INFO : ==> Train loss   : 7.610563
2018-03-11 20:01:52,843 : INFO : ==> Train loss   : 7.276536
2018-03-11 20:03:06,540 : INFO : ==> Train loss   : 6.980911
2018-03-11 20:04:20,264 : INFO : ==> Train loss   : 6.535957
2018-03-11 20:05:36,378 : INFO : ==> Train loss   : 6.220377
2018-03-11 20:06:54,998 : INFO : ==> Train loss   : 5.993176
2018-03-11 20:08:16,043 : INFO : ==> Train loss   : 5.762096
2018-03-11 20:10:02,803 : INFO : ==> Train loss   : 5.388815
2018-03-11 20:11:18,335 : INFO : ==> Train loss   : 5.231802
2018-03-11 20:12:31,668 : INFO : ==> Train loss   : 4.914472
2018-03-11 20:12:31,668 : INFO : done
2018-03-11 20:53:19,924 : INFO : LOG_FILE
2018-03-11 20:53:19,925 : INFO : _________________________________start___________________________________
2018-03-11 20:53:19,927 : INFO : Namespace(batchsize=1, cuda=False, data='data/sst/', emblr=0, epochs=30, fine_grain=1, glove='data/glove/', input_dim=300, lower=True, lr=0.05, mem_dim=150, model_name='constituency', name='default_name', num_classes=5, optim='adagrad', reg=0, saved='saved_model', seed=123, wd=0)
2018-03-11 20:53:19,957 : INFO : ==> SST vocabulary size : 21701
2018-03-11 20:53:20,845 : INFO : _param count_
2018-03-11 20:53:20,846 : INFO : torch.Size([150, 300])
2018-03-11 20:53:20,846 : INFO : torch.Size([150])
2018-03-11 20:53:20,846 : INFO : torch.Size([150, 300])
2018-03-11 20:53:20,846 : INFO : torch.Size([150])
2018-03-11 20:53:20,846 : INFO : torch.Size([150, 150])
2018-03-11 20:53:20,846 : INFO : torch.Size([150])
2018-03-11 20:53:20,846 : INFO : torch.Size([150, 150])
2018-03-11 20:53:20,846 : INFO : torch.Size([150])
2018-03-11 20:53:20,846 : INFO : torch.Size([150, 150])
2018-03-11 20:53:20,847 : INFO : torch.Size([150])
2018-03-11 20:53:20,847 : INFO : torch.Size([150, 150])
2018-03-11 20:53:20,847 : INFO : torch.Size([150])
2018-03-11 20:53:20,847 : INFO : torch.Size([150, 150])
2018-03-11 20:53:20,847 : INFO : torch.Size([150])
2018-03-11 20:53:20,847 : INFO : torch.Size([150, 150])
2018-03-11 20:53:20,847 : INFO : torch.Size([150])
2018-03-11 20:53:20,847 : INFO : torch.Size([150, 150])
2018-03-11 20:53:20,847 : INFO : torch.Size([150])
2018-03-11 20:53:20,847 : INFO : torch.Size([150, 150])
2018-03-11 20:53:20,847 : INFO : torch.Size([150])
2018-03-11 20:53:20,848 : INFO : torch.Size([5, 150])
2018-03-11 20:53:20,848 : INFO : torch.Size([5])
2018-03-11 20:53:20,848 : INFO : sum
2018-03-11 20:53:20,848 : INFO : 272255
2018-03-11 20:53:20,848 : INFO : ____________
2018-03-11 20:54:36,030 : INFO : ==> Train loss   : 24.835587
2018-03-11 20:55:48,425 : INFO : ==> Train loss   : 20.461270
2018-03-11 20:57:01,304 : INFO : ==> Train loss   : 18.707251
2018-03-11 20:58:14,321 : INFO : ==> Train loss   : 17.296130
2018-03-11 20:59:33,809 : INFO : ==> Train loss   : 16.252325
2018-03-11 21:00:48,200 : INFO : ==> Train loss   : 15.313259
2018-03-11 21:02:02,729 : INFO : ==> Train loss   : 14.400619
2018-03-11 21:03:16,707 : INFO : ==> Train loss   : 13.564996
2018-03-11 21:04:31,256 : INFO : ==> Train loss   : 12.851548
2018-03-11 21:05:46,903 : INFO : ==> Train loss   : 12.258131
2018-03-11 21:07:01,111 : INFO : ==> Train loss   : 11.550636
2018-03-11 21:08:13,927 : INFO : ==> Train loss   : 10.926511
2018-03-11 21:09:27,677 : INFO : ==> Train loss   : 10.382691
2018-03-11 21:10:41,730 : INFO : ==> Train loss   : 9.939935
2018-03-11 21:11:55,419 : INFO : ==> Train loss   : 9.415430
2018-03-11 21:13:09,028 : INFO : ==> Train loss   : 8.945571
2018-03-11 21:14:22,338 : INFO : ==> Train loss   : 8.438356
2018-03-11 21:15:39,531 : INFO : ==> Train loss   : 7.934920
2018-03-11 21:16:54,686 : INFO : ==> Train loss   : 7.600375
2018-03-11 21:18:15,796 : INFO : ==> Train loss   : 7.272806
2018-03-11 21:19:31,147 : INFO : ==> Train loss   : 6.921422
2018-03-11 21:20:49,127 : INFO : ==> Train loss   : 6.554998
2018-03-11 21:22:01,781 : INFO : ==> Train loss   : 6.190159
2018-03-11 21:23:30,069 : INFO : ==> Train loss   : 5.819536
2018-03-11 21:25:01,161 : INFO : ==> Train loss   : 5.536951
2018-03-11 21:26:38,621 : INFO : ==> Train loss   : 5.285645
2018-03-11 21:28:06,442 : INFO : ==> Train loss   : 5.010612
2018-03-11 21:29:31,124 : INFO : ==> Train loss   : 4.822595
2018-03-11 21:30:54,345 : INFO : ==> Train loss   : 4.624748
2018-03-11 21:32:05,627 : INFO : ==> Train loss   : 4.578924
2018-03-11 21:32:05,627 : INFO : done
2018-03-15 09:56:46,250 : INFO : LOG_FILE
2018-03-15 09:56:46,251 : INFO : _________________________________start___________________________________
2018-03-15 09:56:46,254 : INFO : Namespace(batchsize=1, cuda=False, data='data/sst/', emblr=0, epochs=30, fine_grain=1, glove='data/glove/', input_dim=300, lower=True, lr=0.05, mem_dim=150, model_name='constituency', name='default_name', num_classes=5, optim='adagrad', reg=0, saved='saved_model', seed=123, wd=0)
2018-03-15 09:56:46,286 : INFO : ==> SST vocabulary size : 21701
2018-03-15 09:56:47,177 : INFO : _param count_
2018-03-15 09:56:47,178 : INFO : torch.Size([150, 300])
2018-03-15 09:56:47,179 : INFO : torch.Size([150])
2018-03-15 09:56:47,179 : INFO : torch.Size([150, 300])
2018-03-15 09:56:47,179 : INFO : torch.Size([150])
2018-03-15 09:56:47,179 : INFO : torch.Size([150, 150])
2018-03-15 09:56:47,179 : INFO : torch.Size([150])
2018-03-15 09:56:47,179 : INFO : torch.Size([150, 150])
2018-03-15 09:56:47,179 : INFO : torch.Size([150])
2018-03-15 09:56:47,179 : INFO : torch.Size([150, 150])
2018-03-15 09:56:47,179 : INFO : torch.Size([150])
2018-03-15 09:56:47,179 : INFO : torch.Size([150, 150])
2018-03-15 09:56:47,179 : INFO : torch.Size([150])
2018-03-15 09:56:47,180 : INFO : torch.Size([150, 150])
2018-03-15 09:56:47,180 : INFO : torch.Size([150])
2018-03-15 09:56:47,180 : INFO : torch.Size([150, 150])
2018-03-15 09:56:47,180 : INFO : torch.Size([150])
2018-03-15 09:56:47,180 : INFO : torch.Size([150, 150])
2018-03-15 09:56:47,180 : INFO : torch.Size([150])
2018-03-15 09:56:47,180 : INFO : torch.Size([150, 150])
2018-03-15 09:56:47,180 : INFO : torch.Size([150])
2018-03-15 09:56:47,180 : INFO : torch.Size([5, 150])
2018-03-15 09:56:47,180 : INFO : torch.Size([5])
2018-03-15 09:56:47,180 : INFO : sum
2018-03-15 09:56:47,180 : INFO : 272255
2018-03-15 09:56:47,180 : INFO : ____________
2018-03-15 09:56:47,247 : INFO : prepare time is 0.9958267211914062
2018-03-15 09:58:02,743 : INFO : ==> Train loss   : 25.076598
2018-03-15 09:59:16,950 : INFO : ==> Train loss   : 20.655247
2018-03-15 10:00:30,554 : INFO : ==> Train loss   : 18.882836
